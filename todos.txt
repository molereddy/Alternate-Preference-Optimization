1. remove local path for llama3.2 from model config
2. Add gibberish evals, FQ V2
3. Add self conf evals
4. Combine above evals to occur during generation
5. Remove self conf evals file from paper_models?